{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Practico N°1\n",
    "## Inteligencia Artificial\n",
    "\n",
    "\n",
    "### Prieto Julian 45065709"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La diferencia mas notable al entrenar ambos conjuntos de datos es que el conjunto A lleva a la convergencia, es decir, alcanza el maximo error elegido, de forma mucho mas rapida que el conjunto de datos B. Este ultimo tarda muchisimo mas tiempo en llegar a dicha convergencia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tener un modelo perfectamente calibrado no implica conseguir una precision perfecto ya que aún así, el modelo podría estar prediciendo erroneamente debido a un umbral de desicion incorrecto, haciendo que clasifique algunos ejemplos como falsos negativos o como falsos positivos. Entonces, por mas que el promedio de de clasificaciones sea perfecto, el modelo se puede estar equivocando en qué casos clasifica como positivos y cuales negativos.\n",
    "Por otro lado, que el modelo tenga una precision perfecta no quiere decir que tenga una calibración perfecta. La precision esta enfocada en la exactitud de las predicciones de clase en base a verdaderos positivos y verdaderos negativos, lo que afecta necesariamente a la calibracion del mismo ya que las probabilidades estimadas pueden llegar a ser inexactas en terminos de reflejar la probabilidad real.\n",
    "\n",
    "\n",
    "\n",
    "1. Un modelo perfectamente calibrado no implica precisión perfecta:\n",
    "\n",
    "La calibración se refiere a la capacidad del modelo para producir estimaciones de probabilidad que reflejen con precisión la probabilidad real de que un ejemplo pertenezca a una clase. Un modelo puede estar perfectamente calibrado en el sentido de que las probabilidades estimadas son muy precisas, pero aún así cometer errores de clasificación. Esto ocurre porque la precisión se refiere a cuántos de los ejemplos clasificados como positivos son verdaderamente positivos (verdaderos positivos) y cuántos de los ejemplos clasificados como negativos son verdaderamente negativos (verdaderos negativos).\n",
    "\n",
    "Por ejemplo, un modelo podría tener probabilidades perfectamente calibradas en el rango (0, 1), pero aún así, debido a un umbral de decisión incorrecto, puede clasificar algunos ejemplos positivos como negativos (falsos negativos) o ejemplos negativos como positivos (falsos positivos), lo que resultaría en una precisión imperfecta.\n",
    "\n",
    "2. Precisión perfecta no implica necesariamente calibración perfecta:\n",
    "\n",
    "Una alta precisión en la clasificación no garantiza que el modelo esté perfectamente calibrado. La precisión se enfoca en la exactitud de las predicciones de clase en términos de verdaderos positivos y verdaderos negativos, pero no necesariamente en la precisión de las probabilidades estimadas.\n",
    "\n",
    "Un modelo puede lograr una alta precisión simplemente asignando un umbral de probabilidad muy alto (por ejemplo, 0.9) para predecir la clase positiva, lo que podría llevar a una precisión alta, pero las probabilidades estimadas aún pueden estar mal calibradas. Esto significa que las probabilidades estimadas pueden ser inexactas en términos de reflejar la probabilidad real de que un ejemplo pertenezca a una clase, especialmente en el rango de probabilidades más bajos.\n",
    "\n",
    "En resumen, la calibración y la precisión son dos aspectos diferentes de la evaluación de un modelo de clasificación binaria. Un modelo puede estar perfectamente calibrado sin lograr precisión perfecta y viceversa. La calibración se refiere a la precisión de las probabilidades estimadas, mientras que la precisión se refiere a la precisión en la clasificación de ejemplos en términos de verdaderos positivos y verdaderos negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La regularizacion L2 o de Ridge es, de manera sencilla, una tecnica utilizada comunmente en la regresion logistica la cual se utiliza para prevenir sobreajustes en los modelos y aumentar el rendimiento de los mismos. Realizar una regularizacion a un modelo puede afectar la calibracion del mismo tanto de manera positiva como de manera negativa, dependiendo del contexto y de la eleccion del hiperparametro de regularizacion Lambda.\n",
    "\n",
    "Por un lado, la regularizacion, como se menciono anteriormente, puede ayudar a disminuir el riesgo de sobreajuste del modelo predictivo haciendo que este generalice mejor y por lo tanto mejore sus predicciones en datos que nunca vió.\n",
    "Por otro lado, la regularizacion tambien puede llegar a simplificar de mas el modelo, llevando a una disminucion de la 'sensibilidad' del modelo a las caracteristicas de los datos y consiguiendo que este no se vea afectado por nuevos datos.\n",
    "\n",
    "Por ultimo, algo muy importante de la regularizacion en la eleccion del hipreparametro Lambda. El efecto que tenga esta tecnica en el modelo depende mucho del valor de este parametro, ya que estableciendolo con un valor muy pequeño puede causar que el modelo se ajuste demasiado a los datos, provocando sobreajuste u overfitting. Pero, dandole un valor muy grande a Lambda aumentara la simpleza del modelo haciendo que este no pueda capturar la complejidad de los datos. \n",
    "En resumidas cuentas, la eleccion del valor del hiperparametro Lambda es de mucha importancia para la regularizacion y debe ser elegido teniendo en cuenta los datos, el modelo elegido y muchas otras cosas para conseguir un efecto positivo en el mismo.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "La regularización L2, también conocida como la regularización de Ridge, es una técnica comúnmente utilizada en la regresión logística y otros modelos de aprendizaje automático para prevenir el sobreajuste y mejorar el rendimiento del modelo. Su efecto en la calibración del modelo de regresión logística puede ser tanto positivo como negativo, dependiendo de la situación y de cómo se ajuste el hiperparámetro de regularización.\n",
    "\n",
    "Efecto positivo en la calibración:\n",
    "\n",
    "Reducción del sobreajuste: La regularización L2 ayuda a reducir el riesgo de sobreajuste del modelo. Cuando un modelo de regresión logística está sobreajustado, es más probable que tenga problemas de calibración en datos de prueba. La inclusión de regularización L2 puede ayudar a que el modelo generalice mejor y, por lo tanto, mejorar la calibración en datos no vistos.\n",
    "\n",
    "\n",
    "Efecto negativo en la calibración:\n",
    "\n",
    "Sesgo en los coeficientes: La regularización L2 introduce un término de penalización en la función objetivo que favorece la simplicidad del modelo al restringir los valores de los coeficientes. Esto puede llevar a una disminución de la sensibilidad del modelo a las características en los datos, lo que podría afectar negativamente su capacidad para modelar correctamente las relaciones subyacentes en los datos.\n",
    "Ajuste del hiperparámetro de regularización (λ): El efecto de la regularización L2 en la calibración depende en gran medida del valor del hiperparámetro de regularización λ. Un valor pequeño de λ permitirá que los coeficientes se ajusten de manera más cercana a los datos de entrenamiento, lo que podría resultar en un modelo con mejor calibración en el conjunto de entrenamiento, pero podría sufrir de sobreajuste en datos de prueba. Por otro lado, un valor grande de λ aumentará la regularización y simplificará el modelo, lo que podría afectar negativamente la calibración si el modelo es demasiado simple para capturar la complejidad de los datos.\n",
    "\n",
    "En resumen, la inclusión de regularización L2 en la función objetivo de la regresión logística puede tener un efecto tanto positivo como negativo en la calibración del modelo. El ajuste adecuado del hiperparámetro de regularización es esencial para lograr un equilibrio entre prevenir el sobreajuste y mantener la calibración adecuada en los datos de prueba. La elección de λ debe basarse en la naturaleza de los datos y en la relación entre el sesgo y la varianza del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tamaño de imagen original: 512 * 512 * 24 (3 colores * 8 bits) = 6.291.456 bits\n",
    "Tamaño de imagen comprimida: 512 * 512 * 4 (log_2(16) = 4) = 1.048.576 bits  3145728\n",
    "Tamano de imagen comprimida: 512 * 512 * 12 (3 colores * 4 bits) = 3.145.728\n",
    "\n",
    "Factor de compresion: 6.291.456 / 1.048.576 = 6\n",
    "Factor de compresion: 6.291.456 / 3.145.728 = 2\n",
    "\n",
    "La imagen comprimida es 6 o 2 veces mas pequeña que la imagen original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolución: 512x512\n",
      "Profundidad de color: RGB bits\n",
      "Número de bits necesarios: 6291456 bits\n",
      "Tamaño en bytes: 786432.0 bytes\n",
      "Tamaño en kilobytes: 768.0 KB\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "imagen_large = Image.open(\"data/peppers-large.tiff\")\n",
    "imagen_comprimida = Image.open(\"data/peppers-compressed.tiff\")\n",
    "\n",
    "ancho, alto = imagen_large.size\n",
    "profundidad_color = imagen_large.mode\n",
    "numero_bits = ancho * alto * (8 * len(profundidad_color))\n",
    "numero_bytes = numero_bits / 8\n",
    "numero_kilobytes = numero_bytes / 1024\n",
    "print(f\"Resolución: {ancho}x{alto}\")\n",
    "print(f\"Profundidad de color: {profundidad_color} bits\")\n",
    "print(f\"Número de bits necesarios: {numero_bits} bits\")\n",
    "print(f\"Tamaño en bytes: {numero_bytes} bytes\")\n",
    "print(f\"Tamaño en kilobytes: {numero_kilobytes} KB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
