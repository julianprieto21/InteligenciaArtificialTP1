{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Practico N°1\n",
    "## Inteligencia Artificial\n",
    "\n",
    "\n",
    "### Prieto Julian 45065709"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La diferencia mas notable al entrenar ambos conjuntos de datos es que el conjunto A lleva a la convergencia, es decir, alcanza el maximo error elegido, de forma mucho mas rapida que el conjunto de datos B. Este ultimo tarda muchisimo mas tiempo en llegar a dicha convergencia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Un modelo perfectamente calibrado no implica precisión perfecta:\n",
    "\n",
    "La calibración se refiere a la capacidad del modelo para producir estimaciones de probabilidad que reflejen con precisión la probabilidad real de que un ejemplo pertenezca a una clase. Un modelo puede estar perfectamente calibrado en el sentido de que las probabilidades estimadas son muy precisas, pero aún así cometer errores de clasificación. Esto ocurre porque la precisión se refiere a cuántos de los ejemplos clasificados como positivos son verdaderamente positivos (verdaderos positivos) y cuántos de los ejemplos clasificados como negativos son verdaderamente negativos (verdaderos negativos).\n",
    "\n",
    "Por ejemplo, un modelo podría tener probabilidades perfectamente calibradas en el rango (0, 1), pero aún así, debido a un umbral de decisión incorrecto, puede clasificar algunos ejemplos positivos como negativos (falsos negativos) o ejemplos negativos como positivos (falsos positivos), lo que resultaría en una precisión imperfecta.\n",
    "\n",
    "2. Precisión perfecta no implica necesariamente calibración perfecta:\n",
    "\n",
    "Una alta precisión en la clasificación no garantiza que el modelo esté perfectamente calibrado. La precisión se enfoca en la exactitud de las predicciones de clase en términos de verdaderos positivos y verdaderos negativos, pero no necesariamente en la precisión de las probabilidades estimadas.\n",
    "\n",
    "Un modelo puede lograr una alta precisión simplemente asignando un umbral de probabilidad muy alto (por ejemplo, 0.9) para predecir la clase positiva, lo que podría llevar a una precisión alta, pero las probabilidades estimadas aún pueden estar mal calibradas. Esto significa que las probabilidades estimadas pueden ser inexactas en términos de reflejar la probabilidad real de que un ejemplo pertenezca a una clase, especialmente en el rango de probabilidades más bajos.\n",
    "\n",
    "En resumen, la calibración y la precisión son dos aspectos diferentes de la evaluación de un modelo de clasificación binaria. Un modelo puede estar perfectamente calibrado sin lograr precisión perfecta y viceversa. La calibración se refiere a la precisión de las probabilidades estimadas, mientras que la precisión se refiere a la precisión en la clasificación de ejemplos en términos de verdaderos positivos y verdaderos negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regularización L2, también conocida como la regularización de Ridge, es una técnica comúnmente utilizada en la regresión logística y otros modelos de aprendizaje automático para prevenir el sobreajuste y mejorar el rendimiento del modelo. Su efecto en la calibración del modelo de regresión logística puede ser tanto positivo como negativo, dependiendo de la situación y de cómo se ajuste el hiperparámetro de regularización.\n",
    "\n",
    "Efecto positivo en la calibración:\n",
    "\n",
    "Reducción del sobreajuste: La regularización L2 ayuda a reducir el riesgo de sobreajuste del modelo. Cuando un modelo de regresión logística está sobreajustado, es más probable que tenga problemas de calibración en datos de prueba. La inclusión de regularización L2 puede ayudar a que el modelo generalice mejor y, por lo tanto, mejorar la calibración en datos no vistos.\n",
    "\n",
    "\n",
    "Efecto negativo en la calibración:\n",
    "\n",
    "Sesgo en los coeficientes: La regularización L2 introduce un término de penalización en la función objetivo que favorece la simplicidad del modelo al restringir los valores de los coeficientes. Esto puede llevar a una disminución de la sensibilidad del modelo a las características en los datos, lo que podría afectar negativamente su capacidad para modelar correctamente las relaciones subyacentes en los datos.\n",
    "Ajuste del hiperparámetro de regularización (λ): El efecto de la regularización L2 en la calibración depende en gran medida del valor del hiperparámetro de regularización λ. Un valor pequeño de λ permitirá que los coeficientes se ajusten de manera más cercana a los datos de entrenamiento, lo que podría resultar en un modelo con mejor calibración en el conjunto de entrenamiento, pero podría sufrir de sobreajuste en datos de prueba. Por otro lado, un valor grande de λ aumentará la regularización y simplificará el modelo, lo que podría afectar negativamente la calibración si el modelo es demasiado simple para capturar la complejidad de los datos.\n",
    "\n",
    "En resumen, la inclusión de regularización L2 en la función objetivo de la regresión logística puede tener un efecto tanto positivo como negativo en la calibración del modelo. El ajuste adecuado del hiperparámetro de regularización es esencial para lograr un equilibrio entre prevenir el sobreajuste y mantener la calibración adecuada en los datos de prueba. La elección de λ debe basarse en la naturaleza de los datos y en la relación entre el sesgo y la varianza del modelo."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
