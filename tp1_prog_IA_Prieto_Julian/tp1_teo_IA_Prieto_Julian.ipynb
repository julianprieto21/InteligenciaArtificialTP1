{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPHjOpSIVp-j"
      },
      "source": [
        "# Trabajo Practico N°1\n",
        "## Inteligencia Artificial\n",
        "\n",
        "\n",
        "### Prieto Julian 45065709"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJBOW9GFVp-m"
      },
      "source": [
        "- 1c: Ruido gaussiano\n",
        "- 3c: Que mierda hacer\n",
        "- 3d: Mas mierda que hacer\n",
        "- 4b: Con que valor calcular el factor de comprension (peso, bits, colores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4n79Mk7rVp-m"
      },
      "source": [
        "# 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsaXTng7Vp-n"
      },
      "source": [
        "## A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmkjii8LVp-n"
      },
      "source": [
        "La diferencia mas notable al entrenar ambos conjuntos de datos es que el conjunto A llega a la convergencia, es decir, alcanza el maximo error elegido, de forma mucho mas rapida que el conjunto de datos B. Este ultimo tarda muchisimo mas tiempo en llegar a dicha convergencia.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMQYkIAYVp-n"
      },
      "source": [
        "## B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH2f08aXVp-o"
      },
      "source": [
        "Habiendo hecho pruebas con los datesets, se logró poder visualizar ambas clasificaciones en una gráficos de puntos.\n",
        "Se dibujó tambien el borde de decisión logrado por el modelo de regresión logistica.\n",
        "\n",
        "### Dataset A\n",
        "![dataset_A.png](attachment:dataset_A.png)\n",
        "\n",
        "### Dataset B\n",
        "![dataset_B.png](attachment:dataset_B.png)\n",
        "\n",
        "Como se puede observar, el dataset B el linealmente separable, lo que indica que se podria lograr una clasificion perfecta con un borde de decision lineal.\n",
        "Teniendo en cuenta esto,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rZdYsm1Vp-o"
      },
      "source": [
        "## C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_w77vpZVp-o"
      },
      "source": [
        "# ------------------\n",
        "\n",
        "El \"learning rate\" (tasa de aprendizaje) es un hiperparámetro crítico en algoritmos de aprendizaje automático, incluyendo modelos de regresión logística. Afecta la velocidad y la estabilidad del proceso de entrenamiento de un modelo de regresión logística de la siguiente manera:\n",
        "\n",
        "Velocidad de convergencia: El valor del learning rate determina qué tan rápido convergerá el algoritmo de optimización hacia los valores óptimos de los parámetros del modelo. Si el learning rate es demasiado pequeño, el modelo puede converger lentamente y requerir más iteraciones para alcanzar una solución óptima. Por otro lado, si el learning rate es demasiado grande, el algoritmo podría no converger o incluso divergir, lo que significa que los parámetros nunca alcanzarán una solución estable.\n",
        "\n",
        "Estabilidad del entrenamiento: Un learning rate adecuado es crucial para la estabilidad del entrenamiento. Si el learning rate es demasiado alto, el modelo puede oscilar alrededor del mínimo óptimo o incluso divergir, lo que se conoce como \"exploding gradients\". Si el learning rate es demasiado pequeño, el modelo puede quedarse atascado en mínimos locales o tomar mucho tiempo en converger.\n",
        "\n",
        "Se probó varios learning rates, pero no se logró mejorar el rendimiento del entrenamiento del algoritmo debido a...\n",
        "\n",
        "# -------------------\n",
        "\n",
        "Se probó disminuyendo el learning rate a cada iteracion [FORMULA] y se logró que ambos datasets convergan. A pesar de esto, los dos tardan entre 9 y 14 millones de iteraciones en hacerloy guiandonos por los resultados, no llegan a predicciones acertadas.\n",
        "\n",
        "# -------------------\n",
        "\n",
        "Escalando las X antes de realizar el entrenamiento no parece tener efecto en la convergencia de los algoritmos. El dataset B sigue sin converger.\n",
        "\n",
        "# -------------------\n",
        "\n",
        "Agregando un termino de regularizacion a la funcion de costo, el gradiente nos queda con un termino de un valor lambda sumando unicamente.\n",
        "Haciendo esto, y probando con varios valores de lambda, se logro que el dataset B llegue a converger, sin modificar el comportamiento del entrenamiento del dataset A.\n",
        "\n",
        "# -------------------\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kEsGEpTVp-p"
      },
      "source": [
        "# 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4VSuc1uVp-p"
      },
      "source": [
        "## A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZogbKqhYVp-p"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keGSINjfVp-p"
      },
      "source": [
        "## B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk87hSBHVp-q"
      },
      "source": [
        "Tener un modelo perfectamente calibrado no implica conseguir una precision perfecto ya que aún así, el modelo podría estar prediciendo erroneamente debido a un umbral de desicion incorrecto, haciendo que clasifique algunos ejemplos como falsos negativos o como falsos positivos. Entonces, por mas que el promedio de de clasificaciones sea perfecto, el modelo se puede estar equivocando en qué casos clasifica como positivos y cuales negativos.\n",
        "Por otro lado, que el modelo tenga una precision perfecta no quiere decir que tenga una calibración perfecta. La precision esta enfocada en la exactitud de las predicciones de clase en base a verdaderos positivos y verdaderos negativos, lo que afecta necesariamente a la calibracion del mismo ya que las probabilidades estimadas pueden llegar a ser inexactas en terminos de reflejar la probabilidad real.\n",
        "\n",
        "\n",
        "\n",
        "1. Un modelo perfectamente calibrado no implica precisión perfecta:\n",
        "\n",
        "La calibración se refiere a la capacidad del modelo para producir estimaciones de probabilidad que reflejen con precisión la probabilidad real de que un ejemplo pertenezca a una clase. Un modelo puede estar perfectamente calibrado en el sentido de que las probabilidades estimadas son muy precisas, pero aún así cometer errores de clasificación. Esto ocurre porque la precisión se refiere a cuántos de los ejemplos clasificados como positivos son verdaderamente positivos (verdaderos positivos) y cuántos de los ejemplos clasificados como negativos son verdaderamente negativos (verdaderos negativos).\n",
        "\n",
        "Por ejemplo, un modelo podría tener probabilidades perfectamente calibradas en el rango (0, 1), pero aún así, debido a un umbral de decisión incorrecto, puede clasificar algunos ejemplos positivos como negativos (falsos negativos) o ejemplos negativos como positivos (falsos positivos), lo que resultaría en una precisión imperfecta.\n",
        "\n",
        "2. Precisión perfecta no implica necesariamente calibración perfecta:\n",
        "\n",
        "Una alta precisión en la clasificación no garantiza que el modelo esté perfectamente calibrado. La precisión se enfoca en la exactitud de las predicciones de clase en términos de verdaderos positivos y verdaderos negativos, pero no necesariamente en la precisión de las probabilidades estimadas.\n",
        "\n",
        "Un modelo puede lograr una alta precisión simplemente asignando un umbral de probabilidad muy alto (por ejemplo, 0.9) para predecir la clase positiva, lo que podría llevar a una precisión alta, pero las probabilidades estimadas aún pueden estar mal calibradas. Esto significa que las probabilidades estimadas pueden ser inexactas en términos de reflejar la probabilidad real de que un ejemplo pertenezca a una clase, especialmente en el rango de probabilidades más bajos.\n",
        "\n",
        "En resumen, la calibración y la precisión son dos aspectos diferentes de la evaluación de un modelo de clasificación binaria. Un modelo puede estar perfectamente calibrado sin lograr precisión perfecta y viceversa. La calibración se refiere a la precisión de las probabilidades estimadas, mientras que la precisión se refiere a la precisión en la clasificación de ejemplos en términos de verdaderos positivos y verdaderos negativos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OITTdx_5Vp-q"
      },
      "source": [
        "## C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uep8u67YVp-q"
      },
      "source": [
        "\n",
        "La regularizacion L2 o de Ridge es, de manera sencilla, una tecnica utilizada comunmente en la regresion logistica la cual se utiliza para prevenir sobreajustes en los modelos y aumentar el rendimiento de los mismos. Realizar una regularizacion a un modelo puede afectar la calibracion del mismo tanto de manera positiva como de manera negativa, dependiendo del contexto y de la eleccion del hiperparametro de regularizacion Lambda.\n",
        "\n",
        "Por un lado, la regularizacion, como se menciono anteriormente, puede ayudar a disminuir el riesgo de sobreajuste del modelo predictivo haciendo que este generalice mejor y por lo tanto mejore sus predicciones en datos que nunca vió.\n",
        "Por otro lado, la regularizacion tambien puede llegar a simplificar de mas el modelo, llevando a una disminucion de la 'sensibilidad' del modelo a las caracteristicas de los datos y consiguiendo que este no se vea afectado por nuevos datos.\n",
        "\n",
        "Por ultimo, algo muy importante de la regularizacion en la eleccion del hipreparametro Lambda. El efecto que tenga esta tecnica en el modelo depende mucho del valor de este parametro, ya que estableciendolo con un valor muy pequeño puede causar que el modelo se ajuste demasiado a los datos, provocando sobreajuste u overfitting. Pero, dandole un valor muy grande a Lambda aumentara la simpleza del modelo haciendo que este no pueda capturar la complejidad de los datos.\n",
        "En resumidas cuentas, la eleccion del valor del hiperparametro Lambda es de mucha importancia para la regularizacion y debe ser elegido teniendo en cuenta los datos, el modelo elegido y muchas otras cosas para conseguir un efecto positivo en el mismo.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "La regularización L2, también conocida como la regularización de Ridge, es una técnica comúnmente utilizada en la regresión logística y otros modelos de aprendizaje automático para prevenir el sobreajuste y mejorar el rendimiento del modelo. Su efecto en la calibración del modelo de regresión logística puede ser tanto positivo como negativo, dependiendo de la situación y de cómo se ajuste el hiperparámetro de regularización.\n",
        "\n",
        "Efecto positivo en la calibración:\n",
        "\n",
        "Reducción del sobreajuste: La regularización L2 ayuda a reducir el riesgo de sobreajuste del modelo. Cuando un modelo de regresión logística está sobreajustado, es más probable que tenga problemas de calibración en datos de prueba. La inclusión de regularización L2 puede ayudar a que el modelo generalice mejor y, por lo tanto, mejorar la calibración en datos no vistos.\n",
        "\n",
        "\n",
        "Efecto negativo en la calibración:\n",
        "\n",
        "Sesgo en los coeficientes: La regularización L2 introduce un término de penalización en la función objetivo que favorece la simplicidad del modelo al restringir los valores de los coeficientes. Esto puede llevar a una disminución de la sensibilidad del modelo a las características en los datos, lo que podría afectar negativamente su capacidad para modelar correctamente las relaciones subyacentes en los datos.\n",
        "Ajuste del hiperparámetro de regularización (λ): El efecto de la regularización L2 en la calibración depende en gran medida del valor del hiperparámetro de regularización λ. Un valor pequeño de λ permitirá que los coeficientes se ajusten de manera más cercana a los datos de entrenamiento, lo que podría resultar en un modelo con mejor calibración en el conjunto de entrenamiento, pero podría sufrir de sobreajuste en datos de prueba. Por otro lado, un valor grande de λ aumentará la regularización y simplificará el modelo, lo que podría afectar negativamente la calibración si el modelo es demasiado simple para capturar la complejidad de los datos.\n",
        "\n",
        "En resumen, la inclusión de regularización L2 en la función objetivo de la regresión logística puede tener un efecto tanto positivo como negativo en la calibración del modelo. El ajuste adecuado del hiperparámetro de regularización es esencial para lograr un equilibrio entre prevenir el sobreajuste y mantener la calibración adecuada en los datos de prueba. La elección de λ debe basarse en la naturaleza de los datos y en la relación entre el sesgo y la varianza del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SNR9SBqVp-r"
      },
      "source": [
        "# 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "160Ma_94Vp-r"
      },
      "source": [
        "## B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNkdrQozVp-r"
      },
      "source": [
        "Tamaño de imagen original: 512 * 512 * 24 (3 colores * 8 bits) = 6.291.456 bits\n",
        "\n",
        "Tamaño de imagen comprimida: 512 * 512 * 4 (log_2(16) = 4) = 1.048.576 bits  3145728\n",
        "\n",
        "Tamano de imagen comprimida: 512 * 512 * 12 (3 colores * 4 bits) = 3.145.728\n",
        "\n",
        "Factor de compresion: 6.291.456 / 1.048.576 = 6\n",
        "Factor de compresion: 6.291.456 / 3.145.728 = 2\n",
        "\n",
        "La imagen comprimida es 6 o 2 veces mas pequeña que la imagen original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1T36KLeVp-r",
        "outputId": "60b1c629-6319-4aa6-be59-84d0c48ac8c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resolución: 512x512\n",
            "Profundidad de color: 3 bits\n",
            "Número de bits necesarios: 6291456 bits\n",
            "Tamaño en bytes: 786432.0 bytes\n",
            "Tamaño en kilobytes: 768.0 KB\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "\n",
        "imagen_large = Image.open(\"data/peppers-large.tiff\")\n",
        "imagen_comprimida = Image.open(\"results/peppers-compressed.jpg\")\n",
        "\n",
        "imagen = imagen_large\n",
        "ancho, alto = imagen.size\n",
        "profundidad_color = imagen.mode\n",
        "numero_bits = ancho * alto * (8 * len(profundidad_color))\n",
        "numero_bytes = numero_bits / 8\n",
        "numero_kilobytes = numero_bytes / 1024\n",
        "print(f\"Resolución: {ancho}x{alto}\")\n",
        "print(f\"Profundidad de color: {len(profundidad_color)} bits\")\n",
        "print(f\"Número de bits necesarios: {numero_bits} bits\")\n",
        "print(f\"Tamaño en bytes: {numero_bytes} bytes\")\n",
        "print(f\"Tamaño en kilobytes: {numero_kilobytes} KB\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}